{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Parameters\n",
    "\n",
    "# select test(1) or training(0)\n",
    "test = 0\n",
    "\n",
    "batch_size = 1\n",
    "number_of_epochs = 100\n",
    "filename = '_defEx_InspMask2' #'_DIV_OK' # _DIV_OK\n",
    "\n",
    "# save csv metrics and disease maps\n",
    "save = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cd /data-synology/anlee/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 435,
     "status": "ok",
     "timestamp": 1691536112346,
     "user": {
      "displayName": "Thomas Keller",
      "userId": "17223430032597201940"
     },
     "user_tz": 420
    },
    "id": "vgh3OIul1RvA",
    "outputId": "e2130622-09d6-4496-d403-59e9c73ad2ae",
    "tags": []
   },
   "outputs": [],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 4870,
     "status": "ok",
     "timestamp": 1691536123960,
     "user": {
      "displayName": "Thomas Keller",
      "userId": "17223430032597201940"
     },
     "user_tz": 420
    },
    "id": "5_BvSxkr3BBw",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# includes&imports\n",
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\" #for CPU \"\"\n",
    "\n",
    "import shutil\n",
    "import nibabel as nib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.ndimage as ndi\n",
    "#import nilearn as nil\n",
    "import tensorflow as tf\n",
    "\n",
    "print(tf.config.list_physical_devices('GPU'))\n",
    "\n",
    "# random seeds\n",
    "np.random.seed(16)\n",
    "tf.random.set_seed(16)\n",
    "tf.keras.utils.set_random_seed(16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0mhg2AoOLcAf"
   },
   "source": [
    "Build an input pipeline with image paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 31949,
     "status": "ok",
     "timestamp": 1689621403431,
     "user": {
      "displayName": "Thomas Keller",
      "userId": "17223430032597201940"
     },
     "user_tz": 420
    },
    "id": "Szib1HgsLasf",
    "outputId": "35cd0da8-264b-4d44-b2bc-696a97668cb6",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# get image pathes for input and target images\n",
    "from tqdm import tqdm\n",
    "\n",
    "root_directory = '/data-synology/anlee/COPDGene/'  # Replace with the actual path to your root directory\n",
    "inputImageName = ('insp_ct_ds.nii') #('insp_ct.nii')\n",
    "outputImageName = ('exp_ct_deform_ds.nii')  # Extensions of the target image files\n",
    "maskInspImageName = ('insp_mask_cat.nii')  # Mask image\n",
    "#maskDefExpImageName = ('exp_mask_deform_cat.nii')  # Mask image\n",
    "\n",
    "\n",
    "def search_images(directory, image_list, name):\n",
    "  for root, dirs, files in tqdm(os.walk(directory)):\n",
    "        for file in files:\n",
    "            if file.endswith(name):\n",
    "                image_path = os.path.join(root, file)\n",
    "                image_list.append(image_path.replace('\\0', ''))  # Add the image path to the list, replace termination character\n",
    "\n",
    "# Create an empty list to store image paths\n",
    "inputImagePath = []\n",
    "outputImagePath = []\n",
    "maskInspImagePath = []\n",
    "#maskDefExpImagePath = []\n",
    "\n",
    "# Call the search_image function with the root directory\n",
    "search_images(root_directory, inputImagePath, inputImageName)\n",
    "search_images(root_directory, outputImagePath, outputImageName)\n",
    "search_images(root_directory, maskInspImagePath, maskInspImageName)\n",
    "#search_images(root_directory, maskDefExpImagePath, maskDefExpImageName)\n",
    "\n",
    "# check if path loaded\n",
    "if inputImagePath:\n",
    "    print(\"Image input paths:\")\n",
    "    for path in inputImagePath[:5]:\n",
    "        print(path)\n",
    "else:\n",
    "    print(\"No image files found in the directory tree.\")\n",
    "\n",
    "if outputImagePath:\n",
    "    print(\"Image ouput paths:\")\n",
    "    for path in outputImagePath[:5]:\n",
    "        print(path)\n",
    "else:\n",
    "    print(\"No image files found in the directory tree.\")\n",
    "    \n",
    "if maskInspImagePath:\n",
    "    print(\"Image mask insp paths:\")\n",
    "    for path in maskInspImagePath[:5]:\n",
    "        print(path)\n",
    "else:\n",
    "    print(\"No image files found in the directory tree.\")\n",
    "    \n",
    "#if maskDefExpImagePath:\n",
    "#    print(\"Image mask defExp paths:\")\n",
    "#    for path in maskDefExpImagePath[:5]:\n",
    "#        print(path)\n",
    "#else:\n",
    "#    print(\"No image files found in the directory tree.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 561,
     "status": "ok",
     "timestamp": 1689621403984,
     "user": {
      "displayName": "Thomas Keller",
      "userId": "17223430032597201940"
     },
     "user_tz": 420
    },
    "id": "HiHMHEnb-r12",
    "outputId": "f7eb6796-8c1c-4eac-d482-3f5d286d959d",
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Convert image paths to lists\n",
    "inputImagePath = list(inputImagePath)\n",
    "outputImagePath = list(outputImagePath)\n",
    "maskInspImagePath = list(maskInspImagePath)\n",
    "#maskDefExpImagePath = list(maskDefExpImagePath)\n",
    "\n",
    "# Split the data into training and test sets list\n",
    "train_input, test_input, train_output, test_output, train_insp_mask, test_insp_mask = train_test_split(\n",
    "    inputImagePath, outputImagePath, maskInspImagePath, test_size=0.3, random_state=42)\n",
    "\n",
    "# Split the data into test and validation sets list\n",
    "val_input, test_input, val_output, test_output, val_insp_mask, test_insp_mask = train_test_split(\n",
    "    test_input, test_output, test_insp_mask, test_size=0.5, random_state=42)\n",
    "\n",
    "print('training data: ' + str(len(train_input)))\n",
    "print('validation data: ' + str(len(val_input)))\n",
    "print('test data: ' + str(len(test_input)))\n",
    "print('train mask inspiratory data: ' + str(len(train_insp_mask)))\n",
    "print('test mask inspiratory data: ' + str(len(test_insp_mask)))\n",
    "#print('train mask expiratory data: ' + str(len(train_exp_mask)))\n",
    "#print('test mask expiratory data: ' + str(len(test_exp_mask)))\n",
    "\n",
    "if train_input:\n",
    "    print(\"Image input paths:\")\n",
    "    for path in train_input[:5]:\n",
    "        print(path)\n",
    "else:\n",
    "    print(\"No image files found in the directory tree.\")\n",
    "\n",
    "if train_output:\n",
    "    print(\"Image ouput paths:\")\n",
    "    for path in train_output[:5]:\n",
    "        print(path)\n",
    "else:\n",
    "    print(\"No image files found in the directory tree.\")\n",
    "    \n",
    "if train_insp_mask:\n",
    "    print(\"Image mask inspiratory paths:\")\n",
    "    for path in train_insp_mask[:5]:\n",
    "        print(path)\n",
    "else:\n",
    "    print(\"No image files found in the directory tree.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Trc3urJsKrYI",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# image function to load images\n",
    "def load_image_scale(file_path):\n",
    "    \n",
    "    # load nibable image\n",
    "    image_data = nib.load(file_path).get_fdata()\n",
    "\n",
    "    # pick middle slice\n",
    "    image = image_data\n",
    "\n",
    "    # convert values\n",
    "    image = (image / 3000)\n",
    "\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# image function to load images\n",
    "def load_image(file_path):\n",
    "\n",
    "    # load nibable image\n",
    "    image_data = nib.load(file_path).get_fdata()\n",
    "    \n",
    "    # pick middle slice\n",
    "    image = image_data\n",
    "    \n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image_mask(file_path):\n",
    "\n",
    "    # load nibable image\n",
    "    image_data = nib.load(file_path).get_fdata()\n",
    "\n",
    "    # pick middle slice\n",
    "    mask = image_data\n",
    "\n",
    "    # create binary image mask\n",
    "    binary_mask_slice = np.where((mask > 0) & (mask < 6), 1, 0)\n",
    "    \n",
    "    return binary_mask_slice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select test or train\n",
    "if test == 1:\n",
    "    test_input_smaller = test_input[0::128]\n",
    "    test_output_smaller = test_output[0::128] \n",
    "    test_mask_insp_smaller = test_insp_mask[0::128]\n",
    "\n",
    "\n",
    "    test_dataset_paths = (test_input_smaller, test_output_smaller)\n",
    "    test_mask_insp_paths = test_mask_insp_smaller\n",
    "\n",
    "    \n",
    "else:\n",
    "    train_dataset_paths = (train_input, train_output)\n",
    "\n",
    "    test_dataset_paths = (test_input, test_output)\n",
    "    test_mask_insp_paths = test_insp_mask\n",
    "\n",
    "# calucalte steps and so on\n",
    "length = len(test_dataset_paths[0])\n",
    "print('length test:')\n",
    "print(length)\n",
    "\n",
    "# calculate steps per epoch and validation steps\n",
    "steps_per_epoch = len(test_dataset_paths[0]) // batch_size\n",
    "print('steps_per_epoch: ' + str(steps_per_epoch))\n",
    "\n",
    "test_steps = len(test_dataset_paths[0]) // batch_size\n",
    "print('test_steps: ' + str(test_steps))\n",
    "\n",
    "# calculate the number of training iterations\n",
    "number_of_steps_total = int(steps_per_epoch * number_of_epochs)\n",
    "print('number_of_steps_total: ' + str(number_of_steps_total))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import shuffle\n",
    "\n",
    "def data_generator(paths, mask_insp_paths, batch_size):\n",
    "    test_input_paths, test_output_paths = paths\n",
    "    \n",
    "    num_samples = len(test_input_paths)\n",
    "    #print(num_samples)\n",
    "    indices = list(range(num_samples))\n",
    "        \n",
    "    for i in range(0, num_samples, batch_size):\n",
    "        batch_indices = indices[i:i+batch_size]\n",
    "\n",
    "        #print(batch_indices)\n",
    "        \n",
    "        test_input_images = []\n",
    "        test_output_images = []\n",
    "        test_mask_images = []\n",
    "\n",
    "        \n",
    "        for idx in batch_indices:\n",
    "            # load mask\n",
    "            mask = load_image_mask(mask_insp_paths[idx])\n",
    "            # load input image\n",
    "            input_image = load_image_scale(test_input_paths[idx])\n",
    "            # mask input image\n",
    "            input_image = input_image * mask\n",
    "            # load deformed exp image\n",
    "            defexp_image = load_image(test_output_paths[idx])\n",
    "\n",
    "            # calculate subtraction and mask it\n",
    "            output_image = defexp_image * mask\n",
    "\n",
    "            # append images to input and output train\n",
    "            test_input_images.append(np.expand_dims(input_image, -1))\n",
    "            test_output_images.append(np.expand_dims(output_image, -1))\n",
    "            test_mask_images.append(np.expand_dims(mask, -1))\n",
    "        \n",
    "        yield np.array(test_input_images), np.array(test_output_images), np.array(test_mask_images)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4ZAc3uLSjLkB"
   },
   "source": [
    "Image generator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create data generators for test and validation\n",
    "test_generator = data_generator(test_dataset_paths, test_mask_insp_paths, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "returned_values = next(test_generator)\n",
    "print(np.array(returned_values).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#inp, out = next(test_generator)\n",
    "#print(inp.shape, out.shape)\n",
    "print(number_of_steps_total)\n",
    "print(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_steps_total = 638000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model HERE WE ARE NOW\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "model_path = f'/data-synology/tkeller/Outputs/3D_nsteps{number_of_steps_total}_batch{batch_size}/'\n",
    "\n",
    "model = load_model(model_path)\n",
    "print('Model loaded')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcualte MSE\n",
    "def compute_mse(ground_truth, prediction):\n",
    "    mse = np.mean((ground_truth - prediction) ** 2)\n",
    "    return mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calcualte airtrapping\n",
    "def compute_airtrapping_per_image(inspiratory, defExp_prediction_image, mask):\n",
    "\n",
    "    subtraction_image = (defExp_prediction_image - inspiratory) * mask\n",
    "    \n",
    "    sub_prediction_image = subtraction_image * 3000\n",
    "\n",
    "    threshold = 100\n",
    "\n",
    "    # count values below threshold\n",
    "    airtrapping_voxels = np.sum((sub_prediction_image < threshold) & (sub_prediction_image != 0))\n",
    "    \n",
    "    # count total total values\n",
    "    total_voxels = np.count_nonzero(sub_prediction_image)\n",
    "\n",
    "    # calcualte percentage airtrapping\n",
    "    percentage_airtrapping = (airtrapping_voxels / total_voxels) * 100\n",
    "    \n",
    "    return percentage_airtrapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dice score\n",
    "# input: deformed expiratory, inpsriatory, predicted\n",
    "def calculate_dice_score(inspiratory, output, masked_predictions, mask):\n",
    "\n",
    "    threshold = 100\n",
    "    \n",
    "    # defExp - inspiratory\n",
    "    sub_real = (output - inspiratory)\n",
    "    mt = np.where(sub_real * 3000 < threshold, 1, 0) * mask\n",
    "\n",
    "    # defExp predict - inspiratory\n",
    "    sub_fake = (masked_predictions - inspiratory)\n",
    "    mp = np.where(sub_fake * 3000 < threshold, 1, 0) * mask\n",
    "    \n",
    "    dice_value = (2 * np.sum(mt * mp)) / (np.sum(mt + mp))\n",
    "    \n",
    "    return dice_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZjvPWbxcL17j",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Initialize placeholders for statistics\n",
    "\n",
    "mse_values = []\n",
    "airtrapping_percentages_fake = []\n",
    "airtrapping_percentages_real = []\n",
    "dice_scores = []\n",
    "\n",
    "# Initialize placeholders for worst case tracking\n",
    "worst_slice_idx = None\n",
    "worst_slice_value = float('inf')  # Assuming you want to minimize the metric\n",
    "worst_slice_batch_idx = None\n",
    "\n",
    "# Loop through generated batches, batch input: inspiratory, batch output: subtraction\n",
    "for batch_input, batch_output, batch_masks in tqdm(test_generator, total=test_steps, desc=\"Processing batches\"):\n",
    "\n",
    "    # predict\n",
    "    predictions = model(batch_input, training=False)\n",
    "\n",
    "    masked_predictions = []\n",
    "    \n",
    "    # maske predictions\n",
    "    for prediction, mask in zip(predictions,batch_masks):\n",
    "        mask_pred = prediction * mask\n",
    "        masked_predictions.append(mask_pred)\n",
    "\n",
    "    # calculate MSE\n",
    "    for defExp, prediction in zip(batch_output, masked_predictions):\n",
    "        mse_values.append(compute_mse(defExp, prediction))\n",
    "\n",
    "    # Iterate through the lists and calculate airtrapping percentages\n",
    "    for inspiratory, prediction, mask in zip(batch_input, masked_predictions, batch_masks):\n",
    "        airtrapping_percentages_fake.append(compute_airtrapping_per_image(inspiratory, prediction, mask))\n",
    "\n",
    "    # Iterate through the lists and calculate airtrapping percentages\n",
    "    for inspiratory, subtraction, mask in zip(batch_input, batch_output, batch_masks):\n",
    "        airtrapping_percentages_real.append(compute_airtrapping_per_image(inspiratory, subtraction, mask))\n",
    "\n",
    "    # Iterate through the lists and calculate dice scores\n",
    "    for inspiratory, output, predictions, mask in zip(batch_input, batch_output, masked_predictions, batch_masks):\n",
    "        dice_scores.append(calculate_dice_score(inspiratory, output, predictions, mask))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "# Assume test_generator, model, compute_mse, and calculate_dice_score are defined elsewhere\n",
    "# Assume compute_airtrapping_per_image can be adapted for 2D slices as needed\n",
    "\n",
    "# Initialize placeholders for statistics\n",
    "mse_values = []\n",
    "airtrapping_percentages_fake = []\n",
    "airtrapping_percentages_real = []\n",
    "dice_scores = []\n",
    "\n",
    "# Initialize placeholders for worst case tracking\n",
    "worst_slice_idx = None\n",
    "worst_slice_value = float('inf')  # Assuming you want to minimize the metric\n",
    "worst_slice_batch_idx = None\n",
    "worst_slice_image_idx = None  # To track the image within the batch\n",
    "\n",
    "# Initialize a list to store detailed information including differences for each slice\n",
    "airtrapping_differences = []\n",
    "\n",
    "# Loop through batches in the generator\n",
    "for batch_idx, (batch_input, batch_output, batch_masks) in enumerate(tqdm(test_generator, total=test_steps, desc=\"Processing batches\")):\n",
    "    predictions = model(batch_input, training=False)\n",
    "\n",
    "    for item_idx in range(batch_input.shape[0]):  # Iterate over items in the batch\n",
    "        image_details = {\n",
    "            'batch_idx': batch_idx, \n",
    "            'item_idx': item_idx, \n",
    "            'worst_difference': 0, \n",
    "            'worst_slice_idx': None, \n",
    "            'slice_details': []\n",
    "        }\n",
    "        \n",
    "        for slice_idx in range(batch_input.shape[1]):  # Iterate over slices in the depth dimension\n",
    "            inspiratory_slice = batch_input[item_idx, slice_idx, :, :]\n",
    "            prediction_slice = predictions[item_idx, slice_idx, :, :]\n",
    "            mask_slice = batch_masks[item_idx, slice_idx, :, :]\n",
    "            \n",
    "            # Calculate true and predicted air trapping percentages\n",
    "            true_airtrapping = compute_airtrapping_per_image(inspiratory_slice, batch_output[item_idx, slice_idx, :, :], mask_slice)\n",
    "            predicted_airtrapping = compute_airtrapping_per_image(inspiratory_slice, prediction_slice, mask_slice)\n",
    "            \n",
    "            # Compute the difference between true and predicted air trapping\n",
    "            difference = abs(true_airtrapping - predicted_airtrapping)\n",
    "            \n",
    "            # Store slice details including true and predicted air trapping values\n",
    "            image_details['slice_details'].append({\n",
    "                'slice_idx': slice_idx,\n",
    "                'true_airtrapping': true_airtrapping,\n",
    "                'predicted_airtrapping': predicted_airtrapping,\n",
    "                'difference': difference\n",
    "            })\n",
    "            \n",
    "            # Update the worst slice for the current image based on the greatest difference\n",
    "            if difference > image_details['worst_difference']:\n",
    "                image_details['worst_difference'] = difference\n",
    "                image_details['worst_slice_idx'] = slice_idx\n",
    "                # Also store true and predicted air trapping values for the worst slice\n",
    "                image_details['worst_true_airtrapping'] = true_airtrapping\n",
    "                image_details['worst_predicted_airtrapping'] = predicted_airtrapping\n",
    "\n",
    "        # Append the current image's details to the list\n",
    "        airtrapping_differences.append(image_details)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Sort images by their worst difference in descending order\n",
    "sorted_images = sorted(airtrapping_differences, key=lambda x: x['worst_difference'], reverse=True)\n",
    "\n",
    "# Extract the worst 20 images\n",
    "worst_20_images = sorted_images[:100]\n",
    "\n",
    "# For each of the worst 20 images, identify and report the worst slice\n",
    "for image in worst_20_images:\n",
    "    print(f\"Batch {image['batch_idx']}, Image {image['item_idx']}: Worst Slice {image['worst_slice_idx']} with Difference {image['worst_difference']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_generator4 = data_generator(test_dataset_paths, test_mask_insp_paths, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Assuming test_generator2 is a predefined generator that can be reset or iterated from the beginning\n",
    "# Reset or reinitialize your generator as needed\n",
    "test_generator2.reset()\n",
    "\n",
    "# Placeholder for the current batch index during iteration through the generator\n",
    "current_batch_idx = -1\n",
    "\n",
    "# Iterate through the generator to find and plot the worst slices\n",
    "for batch_input, batch_output, batch_masks in test_generator4:\n",
    "    current_batch_idx += 1\n",
    "    \n",
    "    # Filter for images from the current batch\n",
    "    filtered_images = [img for img in worst_20_images if img['batch_idx'] == current_batch_idx]\n",
    "    \n",
    "    # If there are no images from this batch in the worst 20, continue to the next batch\n",
    "    if not filtered_images:\n",
    "        continue\n",
    "    \n",
    "    for image_details in filtered_images:\n",
    "        item_idx = image_details['item_idx']\n",
    "        worst_slice_idx = image_details['worst_slice_idx']\n",
    "        worst_true_airtrapping = image_details['worst_true_airtrapping']\n",
    "        worst_predicted_airtrapping = image_details['worst_predicted_airtrapping']\n",
    "        worst_difference = image_details['worst_difference']\n",
    "        worst_slice_mse = image_details['worst_slice_mse']\n",
    "        worst_slice_dice_score = image_details['worst_slice_dice_score']\n",
    "\n",
    "        # Generate predictions for the current batch\n",
    "        predictions = model.predict(batch_input)\n",
    "        \n",
    "        # Process the specific worst slice for visualization\n",
    "        inspiratory_slice = batch_input[item_idx, worst_slice_idx, :, :] * 3000\n",
    "        prediction_slice = predictions[item_idx, worst_slice_idx, :, :] * 3000\n",
    "        ground_truth_slice = batch_output[item_idx, worst_slice_idx, :, :] * 3000\n",
    "\n",
    "        # Use np.squeeze and np.rot90 for simplification\n",
    "        insp_slice_2d = np.rot90(np.squeeze(inspiratory_slice))\n",
    "        pred_slice_2d = np.rot90(np.squeeze(prediction_slice))\n",
    "        gt_slice_2d = np.rot90(np.squeeze(ground_truth_slice))\n",
    "\n",
    "        # Visualization\n",
    "        plt.figure(figsize=(12, 6))\n",
    "\n",
    "        # Display the ground truth slice\n",
    "        plt.subplot(1, 3, 1)\n",
    "        plt.imshow(insp_slice_2d, cmap='gray')\n",
    "        plt.title('Inspiratory Slice')\n",
    "        plt.axis('off')\n",
    "\n",
    "        # Display the prediction slice\n",
    "        plt.subplot(1, 3, 2)\n",
    "        plt.imshow(pred_slice_2d, cmap='gray')\n",
    "        plt.title('Prediction Slice')\n",
    "        plt.axis('off')\n",
    "\n",
    "        # Display the ground truth slice for comparison\n",
    "        plt.subplot(1, 3, 3)\n",
    "        plt.imshow(gt_slice_2d, cmap='gray')\n",
    "        plt.title('Ground Truth Slice')\n",
    "        plt.axis('off')\n",
    "\n",
    "        # Annotations for air trapping, MSE, and Dice scores\n",
    "        plt.suptitle(f\"Batch {image_details['batch_idx']}, Image {image_details['item_idx']}, Slice {worst_slice_idx}\\n\" +\n",
    "                     f\"True Air Trapping: {worst_true_airtrapping:.2f}, Predicted Air Trapping: {worst_predicted_airtrapping:.2f}, \" +\n",
    "                     f\"Difference: {worst_difference:.2f}\\nMSE: {worst_slice_mse:.4f}, Dice Score: {worst_slice_dice_score:.4f}\",\n",
    "                     fontsize=14)\n",
    "\n",
    "        plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, mse in enumerate(mse_values[:5]):\n",
    "    print(f\"MSE at position {idx}:\", mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, airtrapping in enumerate(airtrapping_percentages_fake[:5]):\n",
    "    print(f\"Airtrapping percentage for Prediciton {idx}: {airtrapping}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, airtrapping in enumerate(airtrapping_percentages_real[:5]):\n",
    "    print(f\"Airtrapping percentage for Subtraction {idx}: {airtrapping}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, dicescore in enumerate(dice_scores[:5]):\n",
    "    print(f\"Airtrapping percentage for Subtraction {idx}: {dicescore}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df_metrics = pd.DataFrame(columns=[\"Predicted_Image\", \"MSE\", \"Air-trp 1 [%]\", \"Air-trp 2 [%]\", \"Dice Score\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add values to metric dataframe\n",
    "for i, (mse, airtrapping, airtrapping_check, dice) in enumerate(zip(mse_values, airtrapping_percentages_fake, airtrapping_percentages_real, dice_scores)):\n",
    "    df_metrics.loc[i] = [i, mse, airtrapping_check, airtrapping, dice]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_metrics[:50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if save == 1:\n",
    "    try:\n",
    "        os.mkdir(f\"/data-synology/tkeller/Outputs/3D_nsteps{number_of_steps_total}_batch{batch_size}/test/\")\n",
    "        os.mkdir(f\"/data-synology/tkeller/Outputs/3D_nsteps{number_of_steps_total}_batch{batch_size}/test/metrics/\")\n",
    "        os.mkdir(f\"/data-synology/tkeller/Outputs/3D_nsteps{number_of_steps_total}_batch{batch_size}/test/plots/\")\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(\"An error occurred:\", str(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save to csv\n",
    "if save == 1:\n",
    "    df_metrics.to_csv(f'/data-synology/tkeller/Outputs/3D_nsteps{number_of_steps_total}_batch{batch_size}/test/metrics/metrics.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot metrics of df\n",
    "mean_mse = df_metrics['MSE'].mean()\n",
    "std_mse = df_metrics['MSE'].std()\n",
    "\n",
    "mean_dice = df_metrics['Dice Score'].mean()\n",
    "std_dice = df_metrics['Dice Score'].std()\n",
    "\n",
    "# Represent in the format \"mean ± SD\"\n",
    "mse_str = f\"{mean_mse:.2e} ± {std_mse:.2e}\"\n",
    "dice_str = f\"{mean_dice:.2f} ± {std_dice:.2f}\"\n",
    "\n",
    "print(f'MSE: {mse_str}')\n",
    "print(f'Dice Score: {dice_str}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "# Set the style and size\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.figure(figsize=(10, 8))\n",
    "\n",
    "# Scatter plot\n",
    "sns.scatterplot(x=df_metrics[\"Air-trp 1 [%]\"], y=df_metrics[\"Air-trp 2 [%]\"], alpha=0.6)\n",
    "\n",
    "# Title and labels\n",
    "plt.title(\"Correlation between Air-trapping 1 (True) and Air-trapping 2 (Prediction)\", weight='bold')\n",
    "plt.xlabel(\"Air-trapping 1 [%] (True)\")\n",
    "plt.ylabel(\"Air-trapping 2 [%] (Prediction)\")\n",
    "\n",
    "# Adding the identity line\n",
    "limits = [min(plt.xlim()[0], plt.ylim()[0]), max(plt.xlim()[1], plt.ylim()[1])]\n",
    "plt.plot(limits, limits, 'r-', label='Identity Line')\n",
    "plt.legend()\n",
    "if save == 1:\n",
    "    plt.savefig(f\"/data-synology/tkeller/Outputs/3D_nsteps{number_of_steps_total}_batch{batch_size}/test/plots/Correlation_nsteps{number_of_steps_total}_batch{batch_size}{filename}.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The Bland-Altman plot, also known as a difference plot, is used to visualize the agreement\n",
    "# between two methods or two measurements. It plots the difference between the two measures\n",
    "# against their average.\n",
    "\n",
    "# Bland-Altman data\n",
    "average = (df_metrics[\"Air-trp 1 [%]\"] + df_metrics[\"Air-trp 2 [%]\"]) / 2\n",
    "difference = df_metrics[\"Air-trp 1 [%]\"] - df_metrics[\"Air-trp 2 [%]\"]\n",
    "\n",
    "mean_diff = difference.mean()\n",
    "std_diff = difference.std()\n",
    "\n",
    "# Set the style and size\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.figure(figsize=(10, 8))\n",
    "\n",
    "# Scatter plot\n",
    "sns.scatterplot(x=average, y=difference, alpha=0.6)\n",
    "\n",
    "# Add mean and limits of agreement lines\n",
    "plt.axhline(mean_diff, color='red', linestyle='--', label=f'Mean diff: {mean_diff: .2f}')\n",
    "plt.axhline(mean_diff + 1.96*std_diff, color='blue', linestyle='--', label='Mean diff + 1.96*SD')  #95%\n",
    "plt.axhline(mean_diff - 1.96*std_diff, color='blue', linestyle='--', label='Mean diff - 1.96*SD')\n",
    "\n",
    "# Adding mean values next to the lines using plt.text\n",
    "x_position = max(average)\n",
    "plt.text(x_position, mean_diff + 1.96*std_diff, f'+1.96 SD: {mean_diff + 1.96*std_diff:.2f}', verticalalignment='bottom', horizontalalignment='right', color='blue')\n",
    "plt.text(x_position, mean_diff - 1.96*std_diff, f'-1.96 SD: {mean_diff - 1.96*std_diff:.2f}', verticalalignment='bottom', horizontalalignment='right', color='blue')\n",
    "\n",
    "# Title and labels\n",
    "plt.title(\"Bland-Altman Plot between Air-trapping 1 (True) and Air-trapping 2 (Prediction)\", weight='bold')\n",
    "plt.xlabel(\"Average of Air-trapping 1 [%] (True) and Air-trapping 2 [%] (Prediction)\")\n",
    "plt.ylabel(\"Difference between Air-trapping 1 [%] (True) and Air-trapping 2 [%] (Prediction)\")\n",
    "plt.legend()\n",
    "\n",
    "if save == 1:\n",
    "    plt.savefig(f\"/data-synology/tkeller/Outputs/3D_nsteps{number_of_steps_total}_batch{batch_size}/test/plots/Bland_Altman_nsteps{number_of_steps_total}_batch{batch_size}{filename}.png\")\n",
    "    \n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ICC\n",
    "import pingouin as pg\n",
    "\n",
    "# Reshape dataframe for ICC calculation\n",
    "df_melted = df_metrics.melt(id_vars=['Predicted_Image'], value_vars=['Air-trp 1 [%]', 'Air-trp 2 [%]'], \n",
    "                    var_name='Method', value_name='Measurement')\n",
    "\n",
    "# Calculate ICC\n",
    "icc = pg.intraclass_corr(data=df_melted, targets='Predicted_Image', raters='Method', ratings='Measurement').round(3)\n",
    "\n",
    "print(icc)\n",
    "\n",
    "# Print the ICC value for ICC1\n",
    "print(icc[icc['Type'] == 'ICC1']['ICC'].values[0])\n",
    "\n",
    "icc_val = float(f\"{icc[icc['Type'] == 'ICC1']['ICC'].values[0]:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# table of final statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'MSE: {mse_str}')\n",
    "print(f'ICC: {icc_val}')\n",
    "print(f'Dice Score: {dice_str}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = pd.DataFrame({\n",
    "    'Metric': ['MSE', 'ICC', 'Dice Score'],\n",
    "    'Value': [mse_str, icc_val, dice_str]\n",
    "})\n",
    "\n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter worst cases\n",
    "df_sorted_asce = df_metrics.sort_values(by='Dice Score', ascending=True)\n",
    "print(df_sorted_asce[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create array with worst 20 cases wioth id\n",
    "predicted_image_ids = np.array(df_sorted_asce['Predicted_Image'][:20])\n",
    "\n",
    "# Now predicted_image_ids contains the IDs of interest\n",
    "print(predicted_image_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if save == 1:\n",
    "    results_df.to_csv(f'/data-synology/tkeller/Outputs/3Dnsteps{number_of_steps_total}_batch{batch_size}/test/model_results.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save only disease map\n",
    "save2 = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if save2 == 1:\n",
    "    try:\n",
    "        os.mkdir(f'/data-synology/tkeller/Outputs/3D_nsteps{number_of_steps_total}_batch{batch_size}/DiseaseMap/')\n",
    "    except:\n",
    "        print('Couldnt create directory')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_generator2 = data_generator(test_dataset_paths, test_mask_insp_paths, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.ndimage import gaussian_filter\n",
    "from matplotlib import cm\n",
    "from matplotlib.colors import ListedColormap\n",
    "\n",
    "desired_indices = predicted_image_ids  # Specify the indices of the images you want\n",
    "count = 0  # Initialize the counter\n",
    "\n",
    "# Iterate through the generator\n",
    "for batch_input, batch_output, batch_masks in test_generator2:\n",
    "    #print(f'Batch {count} processed')\n",
    "    for element in desired_indices:\n",
    "        int_element = np.floor(element).astype(int)\n",
    "        print(f'Processing index {int_element}')\n",
    "        \n",
    "        predictions = model(batch_input, training=False)\n",
    "        masked_predictions = []\n",
    "\n",
    "        for prediction, mask in zip(predictions, batch_masks):\n",
    "            mask_pred = prediction * mask\n",
    "            masked_predictions.append(mask_pred)\n",
    "\n",
    "        # Process and plot the first image in each batch (or adjust as needed)\n",
    "        j = 0  # This assumes you're interested in the first image of each batch\n",
    "    \n",
    "        # Select images for creating disease map\n",
    "        insp_ct_ds = (batch_input[j] * 3000)[96] # masked_inspiratory[j] * 3000\n",
    "        exp_ct_deform_ds = (batch_output[j] - batch_input[j])[96] # masked_subtraction[j]\n",
    "        prediction_sub = (masked_predictions[j] - batch_input[j])[96]# masked_predictions[j]\n",
    "        insp_whole = (batch_masks[j])[96] # np.where((test_mask_images[j] > 0) & (test_mask_images[j] < 6), 1, 0)\n",
    "        \n",
    "        # Remove the singular third dimension\n",
    "        insp_ct_ds_2d = np.rot90(np.squeeze(insp_ct_ds), k=-1)\n",
    "        exp_ct_deform_ds_2d = np.rot90(np.squeeze(exp_ct_deform_ds), k=-1)\n",
    "        sub_ct_deform_pred_2d = np.rot90(np.squeeze(prediction_sub), k=-1)\n",
    "        insp_whole_2d = np.rot90(np.squeeze(insp_whole), k=-1)\n",
    "        \n",
    "        # Calculate difference\n",
    "        insp_slc_mask_smooth = gaussian_filter(insp_ct_ds_2d, sigma=1) * insp_whole_2d\n",
    "        diff_slc_mask_smooth = np.abs(gaussian_filter(exp_ct_deform_ds_2d * 3000, sigma=1)) * insp_whole_2d\n",
    "        diff_slc_pred_mask_smooth = np.abs(gaussian_filter(sub_ct_deform_pred_2d * 3000, sigma=1)) * insp_whole_2d\n",
    "        \n",
    "        # Flip images\n",
    "        insp_slc = np.flipud(np.fliplr(insp_ct_ds_2d))\n",
    "        insp_mask = np.flipud(np.fliplr(insp_whole_2d))\n",
    "        insp_slc_mask = np.flipud(np.fliplr(insp_slc_mask_smooth))\n",
    "        diff_slc_pred_mask = np.flipud(np.fliplr(diff_slc_pred_mask_smooth))  # prediction\n",
    "        diff_slc_mask = np.flipud(np.fliplr(diff_slc_mask_smooth))  # ground truth\n",
    "\n",
    "        # Red parts with emphysema\n",
    "        insp_map = cm.get_cmap('Reds', 512)(np.linspace(1,0,512))\n",
    "        insp_map[:,3] = np.linspace(1,0,512)\n",
    "        insp_map[:,0:3] = insp_map[256,0:3]\n",
    "        insp_map=ListedColormap(insp_map)\n",
    "        \n",
    "        # Blue parts with air-trapping\n",
    "        diff_map = cm.get_cmap('Blues', 512)(np.linspace(1,0,512))\n",
    "        diff_map[:,3] = np.linspace(1,0,512)\n",
    "        diff_map[:,0:3] = diff_map[128,0:3]\n",
    "        diff_map=ListedColormap(diff_map)\n",
    "        \n",
    "        # Create the figure\n",
    "        plt.figure(figsize=(20, 10))\n",
    "        \n",
    "        # Display the first image on the left side\n",
    "        plt.subplot(1, 2, 1)\n",
    "        plt.imshow(insp_slc, cmap='gray', vmin=-400-1500, vmax=-400+1500, origin='lower')\n",
    "        plt.imshow(np.ma.masked_where(insp_mask == 0, diff_slc_mask), cmap=diff_map, vmin=0, vmax=100, alpha=0.5)\n",
    "        plt.imshow(np.ma.masked_where(insp_mask == 0, insp_slc_mask), cmap=insp_map, vmin=-1000, vmax=-925, alpha=0.5)\n",
    "        plt.title(f\"Ground-Truth Index {int_element}\", fontweight='bold', fontsize=20)\n",
    "        plt.axis('off')\n",
    "        \n",
    "        # Display the second image on the right side\n",
    "        plt.subplot(1, 2, 2)\n",
    "        plt.imshow(insp_slc, cmap='gray', vmin=-400-1500, vmax=-400+1500, origin='lower')\n",
    "        plt.imshow(np.ma.masked_where(insp_mask == 0, diff_slc_pred_mask), cmap=diff_map, vmin=0, vmax=100, alpha=0.5)\n",
    "        plt.imshow(np.ma.masked_where(insp_mask == 0, insp_slc_mask), cmap=insp_map, vmin=-1000, vmax=-925, alpha=0.5)\n",
    "        plt.title(f\"Prediction Index {int_element}\", fontweight='bold', fontsize=20)\n",
    "        plt.axis('off')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        if save2 == 1:\n",
    "            plt.savefig(f'/data-synology/tkeller/Outputs/3D_nsteps{number_of_steps_total}_batch{batch_size}/DiseaseMap/DiseaseMap_defEx_{count}.png')\n",
    "        plt.show()\n",
    "        plt.close()\n",
    "        #print(int_element\n",
    "\n",
    "    # Increment the counter after each batch\n",
    "    count += 1 \n",
    "\n",
    "    if count > len(desired_indices):\n",
    "        break  # Exit loop after the highest index is surpassed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import nibabel as nib\n",
    "# aff = np.array([[0,-1,0,0],[-1,0,0,0],[0,0,1,0],[0,0,0,1]])\n",
    "# img = nib.Nifti1Image(np.float32(img), aff)\n",
    "# nib.save(img, 'filename.nii')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_generator3 = data_generator(test_dataset_paths, test_mask_insp_paths, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Attempt to extract a single batch from the generator\n",
    "try:\n",
    "    batch_input, batch_output, batch_masks = next(test_generator3)\n",
    "    # Generate predictions for this batch (assuming 'model' is already defined and compiled)\n",
    "    predictions = model.predict(batch_input)\n",
    "    print(f\"Batch shapes -- Input: {batch_input.shape}, Output: {batch_output.shape}, Masks: {batch_masks.shape}, Predictions: {predictions.shape}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error extracting batch from generator or generating predictions: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def save_nifti_with_affine(batch_input, batch_output, predictions, mask, index, output_dir):\n",
    "    \"\"\"\n",
    "    Saves 3D images with a specific affine transformation as NIfTI files.\n",
    "\n",
    "    Parameters:\n",
    "    - batch_input: 4D numpy array of input images [batch_size, depth, height, width].\n",
    "    - batch_output: 4D numpy array of output images [batch_size, depth, height, width].\n",
    "    - predictions: 4D numpy array of model predictions [batch_size, depth, height, width].\n",
    "    - mask: 4D numpy array of masks [batch_size, depth, height, width].\n",
    "    - index: int, index of the image in the batch to save.\n",
    "    - output_dir: str, directory to save the NIfTI files.\n",
    "    \"\"\"\n",
    "    # Affine matrix for flipping x and y axes\n",
    "    affine = np.array([[0, -1, 0, 0],\n",
    "                       [-1, 0, 0, 0],\n",
    "                       [0, 0, 1, 0],\n",
    "                       [0, 0, 0, 1]])\n",
    "\n",
    "    # Ensure output directory exists\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    # Function to save a single 3D image as a NIfTI file\n",
    "    def save_image(data, filename):\n",
    "        # Convert data to float32 as recommended\n",
    "        data_float32 = np.float32(data)\n",
    "        # Create and save the NIfTI image\n",
    "        img = nib.Nifti1Image(data_float32, affine)\n",
    "        nib.save(img, filename)\n",
    "\n",
    "    # Save each image\n",
    "    save_image(batch_input[index], os.path.join(output_dir, f'input_{index}.nii'))\n",
    "    save_image(batch_output[index] - batch_input[index], os.path.join(output_dir, f'output_deformation_{index}.nii'))\n",
    "    save_image(predictions[index] - batch_input[index], os.path.join(output_dir, f'prediction_deformation_{index}.nii'))\n",
    "    save_image(mask[index], os.path.join(output_dir, f'mask_{index}.nii'))\n",
    "\n",
    "# Example usage\n",
    "#batch_index = 0  # Index of the image in the batch you want to save\n",
    "#output_dir = f'/data-synology/tkeller/Outputs/3D_nsteps{number_of_steps_total}_batch{batch_size}/DiseaseMap/'  # Specify your output directory here\n",
    "\n",
    "# Replace the following with the actual data loading code\n",
    "# batch_input, batch_output, predictions, batch_masks = load_your_data()\n",
    "\n",
    "# Call the function with your data and desired index\n",
    "#save_nifti_with_affine(batch_input, batch_output, predictions, batch_masks, batch_index, output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nibabel as nib\n",
    "\n",
    "# Specify the index of the image you want to save, 0 for the first image\n",
    "batch_index = 0\n",
    "\n",
    "# Specify your output directory here, ensure it exists or you have permissions to write to it\n",
    "output_dir = f'/data-synology/tkeller/Outputs/3D_nsteps{number_of_steps_total}_batch{batch_size}/DiseaseMap/'\n",
    "\n",
    "# Now call the function with the first image data\n",
    "save_nifti_with_affine(batch_input, batch_output, predictions, batch_masks, batch_index, output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyN1CR7+GzcjQFmlCHH6fZ8Y",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
